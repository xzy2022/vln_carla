# 传感器与真值查询（UE5）

本文档按“信息来源”对 CARLA UE5 感知能力做工程化分类，并给出最小用法。

参考文档：
- `Docs_Carla_UE5/ref_sensors.md`
- `Docs_Carla_UE5/core_sensors.md`
- `PythonAPI_Carla_UE5/python_api.md`

## 1. IMU 传感器

- Blueprint：`sensor.other.imu`
- 数据类型：`carla.IMUMeasurement`
- 用途：获取线加速度、角速度、航向角（compass）

关键字段：
- `accelerometer`（m/s^2）
- `gyroscope`（rad/s）
- `compass`（rad）
- `frame`、`timestamp`、`transform`

最小示例：

```python
imu_bp = world.get_blueprint_library().find("sensor.other.imu")
imu = world.spawn_actor(imu_bp, carla.Transform(), attach_to=vehicle)
imu.listen(lambda data: print(data.timestamp, data.accelerometer, data.gyroscope, data.compass))
```

常用参数：
- `sensor_tick`：采样周期（仿真秒）
- `noise_*`：噪声与偏置参数

## 2. GNSS 传感器

- Blueprint：`sensor.other.gnss`
- 数据类型：`carla.GnssMeasurement`
- 用途：获取经纬高（由地图地理参考 + 仿真位置换算）

关键字段：
- `latitude`
- `longitude`
- `altitude`
- `frame`、`timestamp`、`transform`

最小示例：

```python
gnss_bp = world.get_blueprint_library().find("sensor.other.gnss")
gnss = world.spawn_actor(gnss_bp, carla.Transform(carla.Location(x=1.0, z=2.8)), attach_to=vehicle)
gnss.listen(lambda data: print(data.timestamp, data.latitude, data.longitude, data.altitude))
```

## 3. 全局真值查询（上帝视角）

这类接口不依赖相机视场，直接读取仿真世界状态。

### 3.1 Actor / Snapshot 真值

- 单个 actor(vehicle的基类)：
  - `actor.get_transform()`
  - `actor.get_velocity()`
  - `actor.get_acceleration()`
  - `actor.get_angular_velocity()`
- 同帧全局：
  - `world.wait_for_tick()` / `world.on_tick(...)` 获取 `WorldSnapshot`
  - 遍历 `ActorSnapshot` 读取同帧状态

示例：

```python
snapshot = world.wait_for_tick()
for snap in snapshot:
    actor = world.get_actor(snap.id)
    if actor and actor.type_id.startswith("vehicle."):
        print(snap.id, snap.get_transform(), snap.get_velocity(), snap.get_acceleration())
```

### 3.2 环境对象与几何

- `world.get_environment_objects(carla.CityObjectLabel.*)`：按语义标签查询环境对象
- `world.get_level_bbs(carla.CityObjectLabel.*)`：查询世界坐标系包围盒
- `world.project_point(location, direction, search_distance)`：射线投射命中查询

适用场景：
- 全局可见性分析
- 高精地图语义核对
- 非视觉路线规划前处理

## 4. 语义感知传感器

这类传感器“受视场约束”，更接近真实车载感知。

### 4.1 语义分割相机

- Blueprint：`sensor.camera.semantic_segmentation`
- 输出：`carla.Image`
- 特点：像素级语义标签（可配合 `carla.ColorConverter` 转换可视化）

### 4.2 实例分割相机

- Blueprint：`sensor.camera.instance_segmentation`
- 输出：`carla.Image`
- 特点：区分类别与实例 ID

### 4.3 语义激光雷达

- Blueprint：`sensor.lidar.ray_cast_semantic`
- 输出：`carla.SemanticLidarMeasurement`
- 单点字段含：
  - `point`（x,y,z）
  - `object_idx`（命中对象 ID）
  - `object_tag`（语义标签）

最小示例：

```python
sem_lidar_bp = world.get_blueprint_library().find("sensor.lidar.ray_cast_semantic")
sem_lidar = world.spawn_actor(sem_lidar_bp, carla.Transform(carla.Location(z=2.5)), attach_to=vehicle)
sem_lidar.listen(lambda data: print(data.frame, len(data)))
```

## 5. 里程计（Odometry）说明

UE5 文档中未提供独立 `odometry` 传感器 blueprint。  
工程实践通常使用：
- 真值位姿 + 真值速度（或 IMU/GNSS）
- 统一时间戳

自行组装为里程计输出（例如 ROS2 `nav_msgs/Odometry`）。

## 6. 选型建议

1. 需要算法对比基准：优先“全局真值查询”。  
2. 需要贴近实车感知：优先“语义/雷达/相机/IMU/GNSS 传感器流”。  
3. 需要同时做定位与评估：并行记录“真值 + IMU + GNSS + 语义传感器”。  
